import requests
import pandas as pd
import time
import logging

from config.loader import TIMEZONE

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


class OKXDataLoader:
    def __init__(self, symbol: str, timeframe: str):
        """
        åˆå§‹åŒ–åŸç”Ÿ OKX æ•°æ®åŠ è½½å™¨
        """
        self.base_url = "https://www.okx.com"
        self.symbol = symbol
        self.timeframe = timeframe
        # ã€æ–°å¢ã€‘ä½¿ç”¨ Session ç»´æŒè¿æ¥æ± ï¼Œæé«˜æ•ˆç‡å¹¶åœ¨æ–­å¼€æ—¶å¯ä»¥é‡ç½®
        self.session = requests.Session()

    def fetch_historical_data(self, limit: int = 5000, max_retries: int = 10) -> pd.DataFrame:
        """
        åŸç”Ÿè°ƒç”¨ OKX V5 æ¥å£æ‹‰å–å†å² K çº¿ (è‡ªåŠ¨åˆ†æ‰¹é˜²å°ç‰ˆ)
        """
        endpoint = "/api/v5/market/history-candles"
        url = f"{self.base_url}{endpoint}"

        all_candles = []
        after = ""

        logging.info(f"å¼€å§‹é€šè¿‡åŸç”Ÿ API æ‰¹é‡æ‹‰å– {self.symbol} {self.timeframe} æ•°æ®ï¼Œç›®æ ‡ {limit} æ ¹...")

        # æ ¸å¿ƒå‚æ•°ï¼šæ¯æ‹‰å–å¤šå°‘æ ¹è¿›è¡Œä¸€æ¬¡æ·±åº¦ä¼‘çœ æ–­ç‚¹
        batch_size_threshold = 1000

        while len(all_candles) < limit:
            # OKX æ¯æ¬¡æœ€å¤§æ”¯æŒ 100 æ ¹
            fetch_size = min(100, limit - len(all_candles))
            params = {
                "instId": self.symbol,
                "bar": self.timeframe,
                "limit": fetch_size
            }
            if after:
                params["after"] = after

            candles = []
            success = False

            for attempt in range(max_retries):
                try:
                    # ä½¿ç”¨ session å‘èµ·è¯·æ±‚
                    response = self.session.get(url, params=params, timeout=15)
                    response.raise_for_status()
                    data = response.json()

                    if data["code"] != "0":
                        raise ValueError(f"OKX ä¸šåŠ¡æŠ¥é”™: {data['msg']}")

                    candles = data["data"]
                    if not candles:
                        success = True
                        break

                    all_candles.extend(candles)
                    after = candles[-1][0]
                    success = True

                    # æ‰“å°ç²¾ç»†è¿›åº¦
                    if len(all_candles) % 500 == 0 or len(all_candles) == limit:
                        logging.info(f"æ‹‰å–è¿›åº¦: {len(all_candles)} / {limit} ...")

                    break  # æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯

                except Exception as e:
                    # ã€æ ¸å¿ƒæœºåˆ¶ 1ã€‘é­é‡ä»£ç†æ–­å¼€æˆ–è¶…æ—¶ï¼Œé”€æ¯å¹¶é‡å»ºåº•å±‚ TCP è¿æ¥ï¼
                    logging.warning(
                        f"ç½‘ç»œé¢ ç°¸ (è¿›åº¦ {len(all_candles)}/{limit}) | ç¬¬ {attempt + 1}/{max_retries} æ¬¡é‡è¯•... æŠ¥é”™: {e}")
                    self.session.close()
                    self.session = requests.Session()

                    # ã€æ ¸å¿ƒæœºåˆ¶ 2ã€‘æŒ‡æ•°é€€é¿ä¼‘çœ ï¼š3ç§’, 5ç§’, 7ç§’... è¶Šå¤±è´¥ä¼‘æ¯è¶Šä¹…
                    sleep_time = 3 + (attempt * 2)
                    time.sleep(sleep_time)

            if not success or not candles:
                logging.error(f"ä¸¥é‡ç½‘ç»œæ•…éšœæˆ–æ— æ›´å¤šæ•°æ®ã€‚åœæ­¢æ‹‰å–ï¼å°†è¿”å›å·²æˆåŠŸè·å–çš„ {len(all_candles)} æ ¹æ•°æ®ã€‚")
                break

            # ã€æ ¸å¿ƒæœºåˆ¶ 3ã€‘å¤§æ‰¹æ¬¡æ·±åº¦ä¼‘çœ é˜²å°é”
            if len(all_candles) > 0 and len(all_candles) % batch_size_threshold == 0:
                logging.info(f"ğŸŸ¢ å·²å®Œæˆä¸€ä¸ªå¤§æ‰¹æ¬¡ ({len(all_candles)}æ ¹)ï¼Œå¼ºåˆ¶ä¼‘çœ  3 ç§’ï¼Œé‡Šæ”¾ä»£ç†ä¸æœåŠ¡å™¨è¿æ¥å‹åŠ›...")
                time.sleep(3)
            else:
                time.sleep(0.15)  # å¹³æ—¶çš„æ­£å¸¸é¢‘ç‡ä¿æŠ¤

        if not all_candles:
            logging.warning("æœªæ‹‰å–åˆ°ä»»ä½•æ•°æ®ï¼")
            return pd.DataFrame()

        # OKX åŸå§‹æ•°æ®æ ¼å¼: [ts, open, high, low, close, vol, volCcy, volCcyQuote, confirm]
        df = pd.DataFrame(all_candles,
                          columns=['timestamp', 'open', 'high', 'low', 'close', 'volume', 'volCcy', 'volCcyQuote',
                                   'confirm'])

        # åªä¿ç•™é‡åŒ–éœ€è¦çš„æ ¸å¿ƒ 6 åˆ—
        df = df[['timestamp', 'open', 'high', 'low', 'close', 'volume']]

        # å°†å­—ç¬¦ä¸²è½¬ä¸ºæµ®ç‚¹æ•°
        for col in ['open', 'high', 'low', 'close', 'volume']:
            df[col] = df[col].astype(float)

        # è½¬æ¢æ—¶é—´æˆ³
        df['timestamp'] = pd.to_datetime(df['timestamp'].astype(int), unit='ms')
        if "+" in TIMEZONE:
            df['timestamp'] += pd.Timedelta(hours=int(TIMEZONE.split("+")[-1]))
        elif "-" in TIMEZONE:
            df['timestamp'] += pd.Timedelta(hours=int(TIMEZONE.split("-")[-1]))

        # åè½¬æ’åºï¼Œæœ€æ—§çš„åœ¨å‰é¢
        df.sort_values('timestamp', ascending=True, inplace=True)
        df.set_index('timestamp', inplace=True)

        logging.info(f"âœ… æˆåŠŸæ„å»º DataFrameï¼Œå…± {len(df)} æ ¹ K çº¿ã€‚æœ€æ—§æ—¶é—´: {df.index[0]} | æœ€æ–°æ—¶é—´: {df.index[-1]}")
        return df